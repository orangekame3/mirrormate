# Configuration for Raspberry Pi deployment
# Connects to Mac Studio via Tailscale for heavy services

providers:
  llm:
    enabled: true
    provider: ollama
    openai:
      model: gpt-4o-mini
      maxTokens: 300
      temperature: 0.7
    ollama:
      model: huggingface.co/mmnga/Llama-3.1-Swallow-8B-Instruct-v0.5-gguf:latest
      baseUrl: "http://studio:11434"  # Mac Studio via Tailscale
      maxTokens: 300
      temperature: 0.7

  tts:
    enabled: true
    provider: voicevox
    openai:
      voice: shimmer
      model: tts-1
      speed: 0.95
    voicevox:
      speaker: 2
      baseUrl: "http://studio:50021"  # Mac Studio via Tailscale

  embedding:
    enabled: true
    provider: ollama
    ollama:
      model: bge-m3
      baseUrl: "http://studio:11434"  # Mac Studio via Tailscale

  memory:
    enabled: true
    rag:
      topK: 8
      threshold: 0.3
    extraction:
      autoExtract: true
      minConfidence: 0.5
