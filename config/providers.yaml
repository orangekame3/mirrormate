providers:
  llm:
    enabled: true
    provider: ollama  # openai or ollama
    openai:
      model: gpt-4o-mini
      maxTokens: 300
      temperature: 0.7
    ollama:
      model: "hf.co/rinna/qwen2.5-bakeneko-32b-instruct-gguf:Q8_0"
      baseUrl: "http://localhost:11434"
      maxTokens: 300
      temperature: 0.7

  tts:
    enabled: true
    provider: voicevox  # openai or voicevox
    openai:
      voice: shimmer  # alloy, echo, fable, onyx, nova, shimmer
      model: tts-1    # tts-1 or tts-1-hd
      speed: 0.95
    voicevox:
      speaker: 2
      baseUrl: "http://localhost:50021"
