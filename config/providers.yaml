providers:
  llm:
    enabled: true
    provider: ollama  # openai or ollama
    openai:
      model: gpt-4o-mini
      maxTokens: 300
      temperature: 0.7
    ollama:
      model: hf.co/rinna/qwen2.5-bakeneko-32b-instruct-gguf:Q8_0
      baseUrl: "http://localhost:11434"
      maxTokens: 300
      temperature: 0.7

  tts:
    enabled: true
    provider: voicevox  # openai or voicevox
    openai:
      voice: shimmer  # alloy, echo, fable, onyx, nova, shimmer
      model: tts-1    # tts-1 or tts-1-hd
      speed: 0.95
    voicevox:
      speaker: 2
      baseUrl: "http://localhost:50021"

  embedding:
    enabled: true
    provider: ollama
    ollama:
      model: bge-m3
      baseUrl: "http://localhost:11434"

  memory:
    enabled: true
    # RAG settings
    rag:
      topK: 8
      threshold: 0.3
    # Memory extraction settings
    extraction:
      autoExtract: true
      minConfidence: 0.5
